{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1372aef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR-AF v0.4.0 loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup: Add package to path (for development mode)\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/aakashroy/Downloads/or-af framework development/or-af')\n",
    "\n",
    "import or_af\n",
    "print(f\"OR-AF v{or_af.__version__} loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a665de31",
   "metadata": {},
   "source": [
    "# OR-AF Framework - Complete Feature Guide\n",
    "\n",
    "This notebook demonstrates all features of OR-AF (Operations Research Agentic Framework):\n",
    "\n",
    "| # | Feature | Description |\n",
    "|---|---------|-------------|\n",
    "| 1 | **MCP Servers** | Create tool servers using the MCP protocol |\n",
    "| 2 | **Agents** | AI agents that connect to MCP servers |\n",
    "| 3 | **Workflows** | Build agent pipelines with graphs |\n",
    "| 4 | **A2A Protocol** | Agent-to-agent communication |\n",
    "| 5 | **Callbacks** | Monitor agent execution |\n",
    "| 6 | **Logging** | Built-in logging utilities |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b88e32",
   "metadata": {},
   "source": [
    "## 1. MCP Servers - Host Your Tools\n",
    "\n",
    "MCP (Model Context Protocol) servers host tools that agents can use. Create a server and register tools with decorators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb3c7f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:07:32 | INFO | MCP Server 'math_tools' initialized (using official MCP SDK)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/26 23:07:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> MCP Server <span style=\"color: #008000; text-decoration-color: #008000\">'math_tools'</span> initialized <span style=\"font-weight: bold\">(</span>using official MCP SDK<span style=\"font-weight: bold\">)</span>              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/26 23:07:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m MCP Server \u001b[32m'math_tools'\u001b[0m initialized \u001b[1m(\u001b[0musing official MCP SDK\u001b[1m)\u001b[0m              \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:07:32 | INFO | Tool 'add' registered with MCP server 'math_tools'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Tool <span style=\"color: #008000; text-decoration-color: #008000\">'add'</span> registered with MCP server <span style=\"color: #008000; text-decoration-color: #008000\">'math_tools'</span>                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Tool \u001b[32m'add'\u001b[0m registered with MCP server \u001b[32m'math_tools'\u001b[0m                        \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:07:32 | INFO | Tool 'multiply' registered with MCP server 'math_tools'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Tool <span style=\"color: #008000; text-decoration-color: #008000\">'multiply'</span> registered with MCP server <span style=\"color: #008000; text-decoration-color: #008000\">'math_tools'</span>                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Tool \u001b[32m'multiply'\u001b[0m registered with MCP server \u001b[32m'math_tools'\u001b[0m                   \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì MCP Server: math_tools\n",
      "  Tools: ['add', 'multiply']\n"
     ]
    }
   ],
   "source": [
    "from or_af import create_mcp_server\n",
    "\n",
    "# Create an MCP server\n",
    "math_server = create_mcp_server(name=\"math_tools\", description=\"Math operations\")\n",
    "\n",
    "# Register tools using @server.tool() decorator\n",
    "@math_server.tool()\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@math_server.tool()\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "print(f\"‚úì MCP Server: {math_server.name}\")\n",
    "print(f\"  Tools: {math_server.list_tools()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a7b0b3",
   "metadata": {},
   "source": [
    "## 2. Agents - Connect to MCP Servers\n",
    "\n",
    "Agents connect to MCP servers to access tools. They use tools to accomplish tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c835c1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì AgentConfig created\n",
      "  System prompt: You are a calculator. Use tools to compu...\n",
      "  Max iterations: 5\n",
      "  Temperature: 0.7\n",
      "\n",
      "üìù To create a full Agent (requires Azure OpenAI credentials):\n",
      "\n",
      "agent = Agent(\n",
      "    name=\"calculator\",\n",
      "    system_prompt=\"...\",\n",
      "    mcp_servers=[math_server]\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from or_af import AgentConfig\n",
    "\n",
    "# Note: Agent requires Azure OpenAI credentials in environment variables.\n",
    "# For demo purposes, we'll show the configuration:\n",
    "\n",
    "config = AgentConfig(\n",
    "    system_prompt=\"You are a calculator. Use tools to compute results.\",\n",
    "    max_iterations=5,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(f\"‚úì AgentConfig created\")\n",
    "print(f\"  System prompt: {config.system_prompt[:40]}...\")\n",
    "print(f\"  Max iterations: {config.max_iterations}\")\n",
    "print(f\"  Temperature: {config.temperature}\")\n",
    "\n",
    "print(\"\\nüìù To create a full Agent (requires Azure OpenAI credentials):\")\n",
    "print('''\n",
    "agent = Agent(\n",
    "    name=\"calculator\",\n",
    "    system_prompt=\"...\",\n",
    "    mcp_servers=[math_server]\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4f488",
   "metadata": {},
   "source": [
    "## 3. Workflows - Build Agent Pipelines\n",
    "\n",
    "Use `WorkflowGraph` to create multi-agent pipelines with conditional routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40d3196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:46 | INFO | Node 'Research' added to workflow 'demo_pipeline'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/26 23:01:46] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Node <span style=\"color: #008000; text-decoration-color: #008000\">'Research'</span> added to workflow <span style=\"color: #008000; text-decoration-color: #008000\">'demo_pipeline'</span>                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/26 23:01:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Node \u001b[32m'Research'\u001b[0m added to workflow \u001b[32m'demo_pipeline'\u001b[0m                         \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:46 | INFO | Node 'Write' added to workflow 'demo_pipeline'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Node <span style=\"color: #008000; text-decoration-color: #008000\">'Write'</span> added to workflow <span style=\"color: #008000; text-decoration-color: #008000\">'demo_pipeline'</span>                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Node \u001b[32m'Write'\u001b[0m added to workflow \u001b[32m'demo_pipeline'\u001b[0m                            \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:46 | INFO | Edge 'Research->Write' added to workflow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Edge <span style=\"color: #008000; text-decoration-color: #008000\">'Research-&gt;Write'</span> added to workflow                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Edge \u001b[32m'Research->Write'\u001b[0m added to workflow                                  \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:46 | INFO | Workflow 'demo_pipeline' compiled successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Workflow <span style=\"color: #008000; text-decoration-color: #008000\">'demo_pipeline'</span> compiled successfully                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Workflow \u001b[32m'demo_pipeline'\u001b[0m compiled successfully                            \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Workflow: demo_pipeline\n",
      "  Nodes: 2, Edges: 1\n"
     ]
    }
   ],
   "source": [
    "from or_af import WorkflowGraph, EdgeCondition\n",
    "\n",
    "# Create simple processing functions for the workflow demo\n",
    "def research_func(input_data):\n",
    "    return f\"Researched: {input_data}\"\n",
    "\n",
    "def write_func(input_data):\n",
    "    return f\"Written report on: {input_data}\"\n",
    "\n",
    "# Build a workflow graph\n",
    "wf = WorkflowGraph(name=\"demo_pipeline\")\n",
    "node1 = wf.add_node(research_func, name=\"Research\", is_entry=True)\n",
    "node2 = wf.add_node(write_func, name=\"Write\", is_exit=True)\n",
    "wf.add_edge(node1, node2, condition=EdgeCondition.ON_SUCCESS)\n",
    "wf.compile()\n",
    "\n",
    "print(f\"‚úì Workflow: {wf.name}\")\n",
    "print(f\"  Nodes: {len(wf.nodes)}, Edges: {len(wf.edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc601e2",
   "metadata": {},
   "source": [
    "### Workflow Visualization\n",
    "\n",
    "OR-AF supports multiple visualization formats: text, ASCII, and Mermaid diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08117360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT FORMAT:\n",
      "============================================================\n",
      "üìä Workflow: demo_pipeline\n",
      "============================================================\n",
      "üî¢ Nodes: 2 | Edges: 1\n",
      "\n",
      "üî∑ NODES:\n",
      "----------------------------------------\n",
      "  ‚è≥ Research üöÄ[ENTRY]\n",
      "  ‚è≥ Write üèÅ[EXIT]\n",
      "\n",
      "üîó EDGES:\n",
      "----------------------------------------\n",
      "  Research ‚úÖ‚îÄ‚îÄ‚ñ∂ Write\n",
      "      Condition: on_success\n",
      "============================================================\n",
      "\n",
      "ASCII FORMAT:\n",
      "+==========================================================+\n",
      "|                      demo_pipeline                       |\n",
      "+==========================================================+\n",
      "\n",
      "+------------------+\n",
      "| Research [ENTRY] |\n",
      "+------------------+\n",
      "     |\n",
      "     | (on_success)\n",
      "     v\n",
      "+------------------+\n",
      "|   Write [EXIT]   |\n",
      "+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Text visualization\n",
    "print(\"TEXT FORMAT:\")\n",
    "print(wf.visualize(format=\"text\"))\n",
    "\n",
    "# ASCII visualization  \n",
    "print(\"\\nASCII FORMAT:\")\n",
    "print(wf.visualize(format=\"ascii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f68ad",
   "metadata": {},
   "source": [
    "### TensorFlow-like Sequential API\n",
    "\n",
    "Use `Sequential` for linear workflows - similar to `tf.keras.Sequential`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607cb3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:49 | INFO | Node 'agent_0' added to workflow 'pipeline'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/26 23:01:49] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Node <span style=\"color: #008000; text-decoration-color: #008000\">'agent_0'</span> added to workflow <span style=\"color: #008000; text-decoration-color: #008000\">'pipeline'</span>                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/26 23:01:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Node \u001b[32m'agent_0'\u001b[0m added to workflow \u001b[32m'pipeline'\u001b[0m                               \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:49 | INFO | Node 'agent_1' added to workflow 'pipeline'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Node <span style=\"color: #008000; text-decoration-color: #008000\">'agent_1'</span> added to workflow <span style=\"color: #008000; text-decoration-color: #008000\">'pipeline'</span>                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Node \u001b[32m'agent_1'\u001b[0m added to workflow \u001b[32m'pipeline'\u001b[0m                               \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:49 | INFO | Node 'agent_2' added to workflow 'pipeline'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Node <span style=\"color: #008000; text-decoration-color: #008000\">'agent_2'</span> added to workflow <span style=\"color: #008000; text-decoration-color: #008000\">'pipeline'</span>                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Node \u001b[32m'agent_2'\u001b[0m added to workflow \u001b[32m'pipeline'\u001b[0m                               \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:49 | INFO | Edge 'agent_0->agent_1' added to workflow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Edge <span style=\"color: #008000; text-decoration-color: #008000\">'agent_0-&gt;agent_1'</span> added to workflow                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Edge \u001b[32m'agent_0->agent_1'\u001b[0m added to workflow                                 \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:49 | INFO | Edge 'agent_1->agent_2' added to workflow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Edge <span style=\"color: #008000; text-decoration-color: #008000\">'agent_1-&gt;agent_2'</span> added to workflow                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Edge \u001b[32m'agent_1->agent_2'\u001b[0m added to workflow                                 \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:49 | INFO | Workflow 'pipeline' compiled successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Workflow <span style=\"color: #008000; text-decoration-color: #008000\">'pipeline'</span> compiled successfully                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Workflow \u001b[32m'pipeline'\u001b[0m compiled successfully                                 \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Sequential: pipeline\n",
      "============================================================\n",
      "üìä Workflow: pipeline\n",
      "============================================================\n",
      "üî¢ Nodes: 3 | Edges: 2\n",
      "\n",
      "üî∑ NODES:\n",
      "----------------------------------------\n",
      "  ‚è≥ agent_0 üöÄ[ENTRY]\n",
      "  ‚è≥ agent_1\n",
      "  ‚è≥ agent_2 üèÅ[EXIT]\n",
      "\n",
      "üîó EDGES:\n",
      "----------------------------------------\n",
      "  agent_0 ‚úÖ‚îÄ‚îÄ‚ñ∂ agent_1\n",
      "      Condition: on_success\n",
      "  agent_1 ‚úÖ‚îÄ‚îÄ‚ñ∂ agent_2\n",
      "      Condition: on_success\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from or_af import Sequential\n",
    "\n",
    "# Define simple processing steps\n",
    "step1 = lambda x: f\"[Step1] {x}\"\n",
    "step2 = lambda x: f\"[Step2] {x}\"\n",
    "step3 = lambda x: f\"[Step3] {x}\"\n",
    "\n",
    "# Create sequential workflow\n",
    "seq = Sequential([step1, step2, step3], name=\"pipeline\")\n",
    "print(f\"‚úì Sequential: {seq.name}\")\n",
    "print(seq.visualize(format=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07032f",
   "metadata": {},
   "source": [
    "## 4. A2A Protocol - Agent Communication\n",
    "\n",
    "A2A (Agent-to-Agent) protocol enables agents to communicate with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27eb1ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:50 | INFO | A2A Agent 'EchoBot' initialized (using official A2A SDK)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/26 23:01:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> A2A Agent <span style=\"color: #008000; text-decoration-color: #008000\">'EchoBot'</span> initialized <span style=\"font-weight: bold\">(</span>using official A2A SDK<span style=\"font-weight: bold\">)</span>                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/26 23:01:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m A2A Agent \u001b[32m'EchoBot'\u001b[0m initialized \u001b[1m(\u001b[0musing official A2A SDK\u001b[1m)\u001b[0m                  \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:50 | INFO | Executor set for A2A Agent 'EchoBot'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executor set for A2A Agent <span style=\"color: #008000; text-decoration-color: #008000\">'EchoBot'</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executor set for A2A Agent \u001b[32m'EchoBot'\u001b[0m                                      \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì A2A Agent: EchoBot\n",
      "  Skills: ['Echo']\n"
     ]
    }
   ],
   "source": [
    "from or_af import create_a2a_agent, SimpleA2AExecutor\n",
    "\n",
    "# Define a handler for the A2A agent\n",
    "async def echo_handler(message: str) -> str:\n",
    "    return f\"Echo: {message}\"\n",
    "\n",
    "# Create an A2A-compliant agent\n",
    "a2a_agent = create_a2a_agent(\n",
    "    name=\"EchoBot\",\n",
    "    description=\"A simple echo agent\",\n",
    "    skills=[{\"id\": \"echo\", \"name\": \"Echo\", \"description\": \"Echoes messages\", \"tags\": [\"echo\"]}]\n",
    ")\n",
    "a2a_agent.set_executor(SimpleA2AExecutor(echo_handler))\n",
    "\n",
    "print(f\"‚úì A2A Agent: {a2a_agent.name}\")\n",
    "print(f\"  Skills: {[s.name for s in a2a_agent.card.skills]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f53b75e",
   "metadata": {},
   "source": [
    "## 5. Callbacks - Monitor Agent Execution\n",
    "\n",
    "Callbacks let you track what happens during agent execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dec445a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Callbacks: ConsoleCallback, MetricsCallback\n",
      "  Global callbacks: 1\n",
      "  Event types with callbacks: 1\n"
     ]
    }
   ],
   "source": [
    "from or_af import ConsoleCallback, MetricsCallback, CallbackHandler, EventType\n",
    "\n",
    "# Available callbacks\n",
    "console_cb = ConsoleCallback()    # Prints events to console\n",
    "metrics_cb = MetricsCallback()    # Tracks execution metrics\n",
    "\n",
    "# Callback handler manages callbacks by event type\n",
    "handler = CallbackHandler()\n",
    "handler.register_global(console_cb.on_event)  # Register for all events\n",
    "handler.register(EventType.AGENT_START, metrics_cb.on_event)\n",
    "\n",
    "print(f\"‚úì Callbacks: ConsoleCallback, MetricsCallback\")\n",
    "print(f\"  Global callbacks: {len(handler._global_callbacks)}\")\n",
    "print(f\"  Event types with callbacks: {sum(1 for v in handler._callbacks.values() if v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee61c3",
   "metadata": {},
   "source": [
    "## 6. Logging - Built-in Utilities\n",
    "\n",
    "OR-AF includes a configurable logging system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121458b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:53 | INFO | This is an info message\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/26 23:01:53] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> This is an info message                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/26 23:01:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m This is an info message                                                   \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:01:53 | WARNING | This is a warning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> This is a warning                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:69</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m This is a warning                                                         \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m69\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Logger configured with level: INFO\n"
     ]
    }
   ],
   "source": [
    "from or_af import get_logger, set_log_level, LogLevel\n",
    "\n",
    "# Get a logger\n",
    "logger = get_logger(\"my_app\")\n",
    "\n",
    "# Set log level (DEBUG, INFO, WARNING, ERROR)\n",
    "set_log_level(LogLevel.INFO)\n",
    "\n",
    "logger.info(\"This is an info message\")\n",
    "logger.warning(\"This is a warning\")\n",
    "\n",
    "print(f\"‚úì Logger configured with level: INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754cb94",
   "metadata": {},
   "source": [
    "## 7. Models - Data Structures\n",
    "\n",
    "OR-AF provides Pydantic models for type-safe data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b13182b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Models available:\n",
      "  AgentConfig: system_prompt='Be helpful'\n",
      "  Message: MessageRole.USER - 'Hello!'\n",
      "  ToolCall: add({'a': 1, 'b': 2})\n",
      "  ToolResult: add = 3\n"
     ]
    }
   ],
   "source": [
    "from or_af import AgentConfig, ToolCall, ToolResult, Message, MessageRole\n",
    "\n",
    "# AgentConfig - Configure agent behavior\n",
    "config = AgentConfig(system_prompt=\"Be helpful\", max_iterations=5)\n",
    "\n",
    "# Message - Chat messages\n",
    "msg = Message(role=MessageRole.USER, content=\"Hello!\")\n",
    "\n",
    "# ToolCall - Track tool invocations\n",
    "tool_call = ToolCall(id=\"call_123\", name=\"add\", arguments={\"a\": 1, \"b\": 2})\n",
    "\n",
    "# ToolResult - Track results\n",
    "tool_result = ToolResult(\n",
    "    tool_call_id=\"call_123\", \n",
    "    tool_name=\"add\", \n",
    "    result=3, \n",
    "    execution_time=0.01\n",
    ")\n",
    "\n",
    "print(f\"‚úì Models available:\")\n",
    "print(f\"  AgentConfig: system_prompt='{config.system_prompt}'\")\n",
    "print(f\"  Message: {msg.role} - '{msg.content}'\")\n",
    "print(f\"  ToolCall: {tool_call.name}({tool_call.arguments})\")\n",
    "print(f\"  ToolResult: {tool_result.tool_name} = {tool_result.result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ec30c6",
   "metadata": {},
   "source": [
    "## 8. Exceptions - Error Handling\n",
    "\n",
    "OR-AF provides specific exceptions for different error types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9669b276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Caught OR-AF error: Tool not found: unknown_tool\n",
      "\n",
      "‚úì Exception hierarchy:\n",
      "  ORAFError (base)\n",
      "    ‚îú‚îÄ‚îÄ AgentError\n",
      "    ‚îú‚îÄ‚îÄ ToolError\n",
      "    ‚îú‚îÄ‚îÄ MCPError\n",
      "    ‚îú‚îÄ‚îÄ WorkflowError\n",
      "    ‚îî‚îÄ‚îÄ A2AError\n"
     ]
    }
   ],
   "source": [
    "from or_af import (\n",
    "    ORAFError,           # Base exception\n",
    "    AgentError,          # Agent-related errors\n",
    "    ToolError,           # Tool errors\n",
    "    MCPError,            # MCP server errors\n",
    "    WorkflowError,       # Workflow errors\n",
    "    A2AError             # A2A protocol errors\n",
    ")\n",
    "\n",
    "# Example: Handle errors gracefully\n",
    "try:\n",
    "    raise ToolError(\"Tool not found: unknown_tool\")\n",
    "except ORAFError as e:\n",
    "    print(f\"‚úì Caught OR-AF error: {e}\")\n",
    "\n",
    "print(f\"\\n‚úì Exception hierarchy:\")\n",
    "print(f\"  ORAFError (base)\")\n",
    "print(f\"    ‚îú‚îÄ‚îÄ AgentError\")\n",
    "print(f\"    ‚îú‚îÄ‚îÄ ToolError\")\n",
    "print(f\"    ‚îú‚îÄ‚îÄ MCPError\")\n",
    "print(f\"    ‚îú‚îÄ‚îÄ WorkflowError\")\n",
    "print(f\"    ‚îî‚îÄ‚îÄ A2AError\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c3289",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Feature | Key Classes | Description |\n",
    "|---------|-------------|-------------|\n",
    "| **MCP** | `MCPServer`, `create_mcp_server` | Host tools on servers |\n",
    "| **Agents** | `Agent` | Connect to MCP servers, run tasks |\n",
    "| **Workflows** | `WorkflowGraph`, `Sequential`, `Parallel` | Build agent pipelines |\n",
    "| **A2A** | `A2AAgent`, `create_a2a_agent` | Agent-to-agent communication |\n",
    "| **Callbacks** | `ConsoleCallback`, `MetricsCallback` | Monitor execution |\n",
    "| **Logging** | `get_logger`, `set_log_level` | Built-in logging |\n",
    "| **Models** | `AgentConfig`, `Message`, `ToolCall` | Type-safe data |\n",
    "| **Exceptions** | `ORAFError`, `AgentError`, etc. | Error handling |\n",
    "\n",
    "**Documentation:** See README.md and QUICKSTART.md for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153ce3f",
   "metadata": {},
   "source": [
    "## Testing Real LLM Execution\n",
    "\n",
    "Now let's test if the LLM integration is working properly with a real agent execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b20eba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment check:\n",
      "  AZURE_OPENAI_ENDPOINT: ‚úì\n",
      "  AZURE_OPENAI_API_KEY: ‚úì\n",
      "  AZURE_OPENAI_DEPLOYMENT_NAME: ‚úì\n",
      "23:07:41 | INFO | Agent 'calculator' connected to MCP server 'math_tools'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/26 23:07:41] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Agent <span style=\"color: #008000; text-decoration-color: #008000\">'calculator'</span> connected to MCP server <span style=\"color: #008000; text-decoration-color: #008000\">'math_tools'</span>                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/26 23:07:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Agent \u001b[32m'calculator'\u001b[0m connected to MCP server \u001b[32m'math_tools'\u001b[0m                   \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Connected to MCP server 'math_tools' (2 tools)\n",
      "23:07:41 | INFO | Agent 'calculator' initialized with model: gpt-5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Agent <span style=\"color: #008000; text-decoration-color: #008000\">'calculator'</span> initialized with model: gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Agent \u001b[32m'calculator'\u001b[0m initialized with model: gpt-\u001b[1;36m5\u001b[0m                          \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Agent created: calculator\n",
      "  Available tools: {'math_tools': ['add', 'multiply']}\n"
     ]
    }
   ],
   "source": [
    "from or_af import Agent\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify environment variables are loaded\n",
    "print(\"Environment check:\")\n",
    "has_endpoint = bool(os.getenv('AZURE_OPENAI_ENDPOINT'))\n",
    "has_key = bool(os.getenv('AZURE_OPENAI_API_KEY'))\n",
    "has_deployment = bool(os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME'))\n",
    "\n",
    "print(f\"  AZURE_OPENAI_ENDPOINT: {'‚úì' if has_endpoint else '‚úó (using default)'}\")\n",
    "print(f\"  AZURE_OPENAI_API_KEY: {'‚úì' if has_key else '‚úó (using default)'}\")\n",
    "print(f\"  AZURE_OPENAI_DEPLOYMENT_NAME: {'‚úì' if has_deployment else '‚úó (using default)'}\")\n",
    "\n",
    "# Create a real agent with the math server\n",
    "calculator_agent = Agent(\n",
    "    name=\"calculator\",\n",
    "    system_prompt=\"You are a helpful calculator assistant. Use the available tools to perform calculations.\",\n",
    "    mcp_servers=[math_server],\n",
    "    max_iterations=5\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Agent created: {calculator_agent.name}\")\n",
    "print(f\"  Available tools: {calculator_agent.list_available_tools()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4751d95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Calculate 15 multiplied by 23, then add 100 to the result\n",
      "\n",
      "Running agent...\n",
      "\n",
      "23:07:49 üöÄ agent_start \n",
      "23:07:49 | INFO | Agent started with task: Calculate 15 multiplied by 23, then add 100 to the result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/26 23:07:49] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Agent started with task: Calculate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> multiplied by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, then add <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> to   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         the result                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/26 23:07:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Agent started with task: Calculate \u001b[1;36m15\u001b[0m multiplied by \u001b[1;36m23\u001b[0m, then add \u001b[1;36m100\u001b[0m to   \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         the result                                                                \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:07:49 üîÑ iteration_start [1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/26 23:07:56] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py:1025</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://bimigration.openai.azure.com/openai/deployments/gpt-5/chat/com</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">pletions?api-version=2024-12-01-preview</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/26 23:07:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                     \u001b[2m_client.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m1025\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://bimigration.openai.azure.com/openai/deployments/gpt-5/chat/com\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mpletions?api-\u001b[0m\u001b[4;94mversion\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94m2024\u001b[0m\u001b[4;94m-12-01-preview\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m              \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:07:56 üìù stream_chunk \n",
      "23:07:56 üí≠ thinking [1]\n",
      "23:07:56 ‚úì iteration_end [1]\n",
      "23:07:56 | INFO | Task completed in 1 iteration(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Task completed in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">iteration</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span>                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Task completed in \u001b[1;36m1\u001b[0m \u001b[1;35miteration\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m                                          \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:07:56 üèÅ agent_end \n",
      "23:07:56 | INFO | Agent finished. Success: True, Duration: 6.61s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Agent finished. Success: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, Duration: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.</span>61s                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Agent finished. Success: \u001b[3;92mTrue\u001b[0m, Duration: \u001b[1;36m6.\u001b[0m61s                            \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Agent completed!\n",
      "Final result: task='Calculate 15 multiplied by 23, then add 100 to the result' response='445' iterations=[IterationState(iteration_number=1, tool_calls=[], tool_results=[], thinking='445', response='445', start_time=datetime.datetime(2026, 1, 31, 23, 7, 49, 837535), end_time=datetime.datetime(2026, 1, 31, 23, 7, 56, 442127))] total_tool_calls=0 success=True error_message=None start_time=datetime.datetime(2026, 1, 31, 23, 7, 49, 836118) end_time=datetime.datetime(2026, 1, 31, 23, 7, 56, 447855)\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with a calculation task\n",
    "task = \"Calculate 15 multiplied by 23, then add 100 to the result\"\n",
    "\n",
    "print(f\"Task: {task}\\n\")\n",
    "print(\"Running agent...\\n\")\n",
    "\n",
    "# Run the agent\n",
    "result = calculator_agent.run(task)\n",
    "\n",
    "print(f\"\\n‚úì Agent completed!\")\n",
    "print(f\"Final result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbecc9fe",
   "metadata": {},
   "source": [
    "## Advanced Workflow with Graph Visualization\n",
    "\n",
    "Let's create a more complex workflow with multiple agents and visualize the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2492d8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:08:29 | INFO | Node 'Research' added to workflow 'multi_agent_pipeline'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/26 23:08:29] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Node <span style=\"color: #008000; text-decoration-color: #008000\">'Research'</span> added to workflow <span style=\"color: #008000; text-decoration-color: #008000\">'multi_agent_pipeline'</span>                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/26 23:08:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Node \u001b[32m'Research'\u001b[0m added to workflow \u001b[32m'multi_agent_pipeline'\u001b[0m                  \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:08:29 | INFO | Node 'Analysis' added to workflow 'multi_agent_pipeline'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Node <span style=\"color: #008000; text-decoration-color: #008000\">'Analysis'</span> added to workflow <span style=\"color: #008000; text-decoration-color: #008000\">'multi_agent_pipeline'</span>                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Node \u001b[32m'Analysis'\u001b[0m added to workflow \u001b[32m'multi_agent_pipeline'\u001b[0m                  \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:08:29 | INFO | Node 'Writer' added to workflow 'multi_agent_pipeline'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Node <span style=\"color: #008000; text-decoration-color: #008000\">'Writer'</span> added to workflow <span style=\"color: #008000; text-decoration-color: #008000\">'multi_agent_pipeline'</span>                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Node \u001b[32m'Writer'\u001b[0m added to workflow \u001b[32m'multi_agent_pipeline'\u001b[0m                    \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:08:29 | INFO | Node 'Reviewer' added to workflow 'multi_agent_pipeline'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Node <span style=\"color: #008000; text-decoration-color: #008000\">'Reviewer'</span> added to workflow <span style=\"color: #008000; text-decoration-color: #008000\">'multi_agent_pipeline'</span>                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Node \u001b[32m'Reviewer'\u001b[0m added to workflow \u001b[32m'multi_agent_pipeline'\u001b[0m                  \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:08:29 | INFO | Edge 'Research->Analysis' added to workflow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Edge <span style=\"color: #008000; text-decoration-color: #008000\">'Research-&gt;Analysis'</span> added to workflow                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Edge \u001b[32m'Research->Analysis'\u001b[0m added to workflow                               \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:08:29 | INFO | Edge 'Analysis->Writer' added to workflow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Edge <span style=\"color: #008000; text-decoration-color: #008000\">'Analysis-&gt;Writer'</span> added to workflow                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Edge \u001b[32m'Analysis->Writer'\u001b[0m added to workflow                                 \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:08:29 | INFO | Edge 'Writer->Reviewer' added to workflow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Edge <span style=\"color: #008000; text-decoration-color: #008000\">'Writer-&gt;Reviewer'</span> added to workflow                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Edge \u001b[32m'Writer->Reviewer'\u001b[0m added to workflow                                 \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:08:29 | INFO | Workflow 'multi_agent_pipeline' compiled successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Workflow <span style=\"color: #008000; text-decoration-color: #008000\">'multi_agent_pipeline'</span> compiled successfully                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Workflow \u001b[32m'multi_agent_pipeline'\u001b[0m compiled successfully                     \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Complex Workflow created: multi_agent_pipeline\n",
      "  Nodes: 4\n",
      "  Edges: 3\n",
      "  Entry node: Research\n",
      "  Exit nodes: ['Reviewer']\n"
     ]
    }
   ],
   "source": [
    "# Create a multi-agent workflow\n",
    "from or_af import WorkflowGraph, EdgeCondition\n",
    "\n",
    "# Create different agent functions for the workflow\n",
    "def research_agent(task):\n",
    "    \"\"\"Simulates a research agent\"\"\"\n",
    "    print(f\"üîç Research Agent: Gathering information on '{task}'\")\n",
    "    return f\"Research data for: {task}\"\n",
    "\n",
    "def analysis_agent(data):\n",
    "    \"\"\"Simulates an analysis agent\"\"\"\n",
    "    print(f\"üìä Analysis Agent: Analyzing data\")\n",
    "    return f\"Analysis of: {data}\"\n",
    "\n",
    "def writer_agent(analysis):\n",
    "    \"\"\"Simulates a writer agent\"\"\"\n",
    "    print(f\"‚úçÔ∏è  Writer Agent: Creating report\")\n",
    "    return f\"Report: {analysis}\"\n",
    "\n",
    "def reviewer_agent(report):\n",
    "    \"\"\"Simulates a reviewer agent\"\"\"\n",
    "    print(f\"üëÅÔ∏è  Reviewer Agent: Reviewing report\")\n",
    "    return f\"Reviewed: {report}\"\n",
    "\n",
    "# Build a complex workflow graph\n",
    "complex_wf = WorkflowGraph(name=\"multi_agent_pipeline\")\n",
    "\n",
    "# Add nodes\n",
    "research = complex_wf.add_node(research_agent, name=\"Research\", is_entry=True)\n",
    "analysis = complex_wf.add_node(analysis_agent, name=\"Analysis\")\n",
    "writer = complex_wf.add_node(writer_agent, name=\"Writer\")\n",
    "reviewer = complex_wf.add_node(reviewer_agent, name=\"Reviewer\", is_exit=True)\n",
    "\n",
    "# Add edges with conditions\n",
    "complex_wf.add_edge(research, analysis, condition=EdgeCondition.ON_SUCCESS)\n",
    "complex_wf.add_edge(analysis, writer, condition=EdgeCondition.ON_SUCCESS)\n",
    "complex_wf.add_edge(writer, reviewer, condition=EdgeCondition.ON_SUCCESS)\n",
    "\n",
    "# Compile the workflow\n",
    "complex_wf.compile()\n",
    "\n",
    "print(f\"‚úì Complex Workflow created: {complex_wf.name}\")\n",
    "print(f\"  Nodes: {len(complex_wf.nodes)}\")\n",
    "print(f\"  Edges: {len(complex_wf.edges)}\")\n",
    "print(f\"  Entry node: {complex_wf.entry_node.name if complex_wf.entry_node else 'None'}\")\n",
    "print(f\"  Exit nodes: {[complex_wf.nodes[n].name for n in complex_wf.exit_nodes]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ced2b0",
   "metadata": {},
   "source": [
    "### Workflow Graph Visualization\n",
    "\n",
    "**This is a key feature of OR-AF!** The framework provides multiple visualization formats to help you understand your workflow structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc6fa8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEXT VISUALIZATION\n",
      "============================================================\n",
      "============================================================\n",
      "üìä Workflow: multi_agent_pipeline\n",
      "============================================================\n",
      "üî¢ Nodes: 4 | Edges: 3\n",
      "\n",
      "üî∑ NODES:\n",
      "----------------------------------------\n",
      "  ‚è≥ Research üöÄ[ENTRY]\n",
      "  ‚è≥ Analysis\n",
      "  ‚è≥ Writer\n",
      "  ‚è≥ Reviewer üèÅ[EXIT]\n",
      "\n",
      "üîó EDGES:\n",
      "----------------------------------------\n",
      "  Research ‚úÖ‚îÄ‚îÄ‚ñ∂ Analysis\n",
      "      Condition: on_success\n",
      "  Analysis ‚úÖ‚îÄ‚îÄ‚ñ∂ Writer\n",
      "      Condition: on_success\n",
      "  Writer ‚úÖ‚îÄ‚îÄ‚ñ∂ Reviewer\n",
      "      Condition: on_success\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ASCII GRAPH VISUALIZATION\n",
      "============================================================\n",
      "+==========================================================+\n",
      "|                   multi_agent_pipeline                   |\n",
      "+==========================================================+\n",
      "\n",
      "+------------------+\n",
      "| Research [ENTRY] |\n",
      "+------------------+\n",
      "     |\n",
      "     | (on_success)\n",
      "     v\n",
      "+------------------+\n",
      "|     Analysis     |\n",
      "+------------------+\n",
      "     |\n",
      "     | (on_success)\n",
      "     v\n",
      "+------------------+\n",
      "|      Writer      |\n",
      "+------------------+\n",
      "     |\n",
      "     | (on_success)\n",
      "     v\n",
      "+------------------+\n",
      "| Reviewer [EXIT]  |\n",
      "+------------------+\n",
      "\n",
      "============================================================\n",
      "MERMAID DIAGRAM (for documentation)\n",
      "============================================================\n",
      "```mermaid\n",
      "flowchart TD\n",
      "    Research[[\"üöÄ Research\"]]\n",
      "    Analysis[\"Analysis\"]\n",
      "    Writer[\"Writer\"]\n",
      "    Reviewer((\"Reviewer üèÅ\"))\n",
      "\n",
      "    Research -->|on_success| Analysis\n",
      "    Analysis -->|on_success| Writer\n",
      "    Writer -->|on_success| Reviewer\n",
      "\n",
      "    %% Styling\n",
      "    classDef entry fill:#90EE90,stroke:#228B22\n",
      "    classDef exit fill:#FFB6C1,stroke:#DC143C\n",
      "    classDef mcp fill:#E6E6FA,stroke:#9370DB\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEXT VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(complex_wf.visualize(format=\"text\"))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ASCII GRAPH VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(complex_wf.visualize(format=\"ascii\"))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MERMAID DIAGRAM (for documentation)\")\n",
    "print(\"=\" * 60)\n",
    "print(complex_wf.visualize(format=\"mermaid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11120668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXECUTING WORKFLOW\n",
      "============================================================\n",
      "23:08:43 | INFO | Executing node: Research\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/31/26 23:08:43] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing node: Research                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/31/26 23:08:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing node: Research                                                  \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Research Agent: Gathering information on 'AI and Machine Learning trends'\n",
      "23:08:43 | INFO | Executing node: Analysis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing node: Analysis                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing node: Analysis                                                  \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Analysis Agent: Analyzing data\n",
      "23:08:43 | INFO | Executing node: Writer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing node: Writer                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing node: Writer                                                    \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úçÔ∏è  Writer Agent: Creating report\n",
      "23:08:43 | INFO | Executing node: Reviewer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Executing node: Reviewer                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Executing node: Reviewer                                                  \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëÅÔ∏è  Reviewer Agent: Reviewing report\n",
      "23:08:43 | INFO | Workflow 'multi_agent_pipeline' execution completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Workflow <span style=\"color: #008000; text-decoration-color: #008000\">'multi_agent_pipeline'</span> execution completed                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logger.py:65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Workflow \u001b[32m'multi_agent_pipeline'\u001b[0m execution completed                       \u001b[2mlogger.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Workflow execution complete!\n",
      "Final result: {'workflow_id': '74c15e23-0cad-4182-89dd-d0e2b9e2e3bf', 'workflow_name': 'multi_agent_pipeline', 'input': 'AI and Machine Learning trends', 'results': {'71903b4d-11db-49b7-942e-16f70af06fe1': NodeResult(node_id='71903b4d-11db-49b7-942e-16f70af06fe1', status=<NodeStatus.COMPLETED: 'completed'>, output='Research data for: AI and Machine Learning trends', error=None, execution_time=2.193450927734375e-05, timestamp=datetime.datetime(2026, 1, 31, 23, 8, 43, 963857)), '77d8b3fd-3729-45ba-9ad3-c45076683043': NodeResult(node_id='77d8b3fd-3729-45ba-9ad3-c45076683043', status=<NodeStatus.COMPLETED: 'completed'>, output='Analysis of: Research data for: AI and Machine Learning trends', error=None, execution_time=1.5020370483398438e-05, timestamp=datetime.datetime(2026, 1, 31, 23, 8, 43, 964882)), '7d6861fd-cd2b-4e7c-a0c3-3aaf65905d7e': NodeResult(node_id='7d6861fd-cd2b-4e7c-a0c3-3aaf65905d7e', status=<NodeStatus.COMPLETED: 'completed'>, output='Report: Analysis of: Research data for: AI and Machine Learning trends', error=None, execution_time=1.4066696166992188e-05, timestamp=datetime.datetime(2026, 1, 31, 23, 8, 43, 965805)), '23feebaf-c1a3-4745-a628-c116788e5230': NodeResult(node_id='23feebaf-c1a3-4745-a628-c116788e5230', status=<NodeStatus.COMPLETED: 'completed'>, output='Reviewed: Report: Analysis of: Research data for: AI and Machine Learning trends', error=None, execution_time=1.1920928955078125e-05, timestamp=datetime.datetime(2026, 1, 31, 23, 8, 43, 966568))}, 'execution_order': ['71903b4d-11db-49b7-942e-16f70af06fe1', '77d8b3fd-3729-45ba-9ad3-c45076683043', '7d6861fd-cd2b-4e7c-a0c3-3aaf65905d7e', '23feebaf-c1a3-4745-a628-c116788e5230'], 'final_outputs': [NodeResult(node_id='23feebaf-c1a3-4745-a628-c116788e5230', status=<NodeStatus.COMPLETED: 'completed'>, output='Reviewed: Report: Analysis of: Research data for: AI and Machine Learning trends', error=None, execution_time=1.1920928955078125e-05, timestamp=datetime.datetime(2026, 1, 31, 23, 8, 43, 966568))], 'success': True, 'timestamp': datetime.datetime(2026, 1, 31, 23, 8, 43, 966573)}\n"
     ]
    }
   ],
   "source": [
    "# Execute the workflow\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXECUTING WORKFLOW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = complex_wf.run(\"AI and Machine Learning trends\")\n",
    "\n",
    "print(f\"\\n‚úì Workflow execution complete!\")\n",
    "print(f\"Final result: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
